# Toxic Comment Classification
<br/><br/>
A large number of Wikipedia comments are provided which have been labeled by human raters for toxic behavior.  The problem has only one predictor variable, 'comment_text', which is to be labeled or classified with respect to six target variables.
<br/><br/>
<b>The target variables are the following types of toxicity:</b>
<br/><br/>
<i>toxic<br/>
severe toxic<br/>
obscene<br/>
threat<br/>
insult<br/>
identity hate<br/><br/></i>
The training set consists of around 159,000+ labeled comments (observations) and the test set consists of around 153,000+ comments to be labeled.
<br/><br/>
<b>The goal is to create a model which predicts a probability of each type of toxicity for each comment.</b>
